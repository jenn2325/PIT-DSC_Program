---
title: "PIT-DSC Parsing Science Policy Issues"
date: "7/30/2021"
---

The parsing of each target data value follows the same steps.

1. Initializing path where all community health profiles are located, load libraries,initialize areas, and creating an empty matrix.
2. Iterate through the path and extract target value.
3. Clean data, and return a final data frame.
### Libraries 
```{r message=FALSE}
library(tabulizer)
library(plyr)
library(tidyverse)
library(pdftools)
library(tm)
```



## Who We Are(demographic Data)

A newer data was found on Community District Profiles [websites](https://planninglabs.carto.com/api/v2/sql?format=csv&q=SELECT%20cartodb_id,the_geom,the_geom_webmercator,acres,acs_tooltip,acs_tooltip_2,acs_tooltip_3,area_sqmi,borocd,cb_email,cb_website,cd_full_title,cd_short_title,cd_son_fy2018,cd_tot_bldgs,cd_tot_resunits,count_hosp_clinic,count_libraries,count_parks,count_public_schools,crime_count,crime_count_boro,crime_count_nyc,crime_per_1000,crime_per_1000_boro,crime_per_1000_nyc,female_10_14,female_15_19,female_20_24,female_25_29,female_30_34,female_35_39,female_40_44,female_45_49,female_5_9,female_50_54,female_55_59,female_60_64,female_65_69,female_70_74,female_75_79,female_80_84,female_85_over,female_under_5,fp_100_area,fp_100_bldg,fp_100_cost_burden,fp_100_cost_burden_value,fp_100_mhhi,fp_100_mortg_value,fp_100_openspace,fp_100_ownerocc,fp_100_ownerocc_value,fp_100_permortg,fp_100_pop,fp_100_rent_burden,fp_100_rent_burden_value,fp_100_resunits,fp_100_openspace2,fp_500_bldg,fp_500_cost_burden,fp_500_cost_burden_value,fp_500_mhhi,fp_500_mortg_value,fp_500_openspace,fp_500_ownerocc,fp_500_ownerocc_value,fp_500_permortg,fp_500_pop,fp_500_rent_burden,fp_500_rent_burden_value,fp_500_resunits,lep_rate,lep_rate_boro,lep_rate_nyc,lot_area_commercial_office,lot_area_industrial_manufacturing,lot_area_mixed_use,lot_area_open_space,lot_area_other_no_data,lot_area_parking,lot_area_public_facility_institution,lot_area_res_1_2_family_bldg,lot_area_res_multifamily_elevator,lot_area_res_multifamily_walkup,lot_area_transportation_utility,lot_area_vacant,lots_commercial_office,lots_industrial_manufacturing,lots_mixed_use,lots_open_space,lots_other_no_data,lots_parking,lots_public_facility_institution,lots_res_1_2_family_bldg,lots_res_multifamily_elevator,lots_res_multifamily_walkup,lots_total,lots_transportation_utility,lots_vacant,male_10_14,male_15_19,male_20_24,male_25_29,male_30_34,male_35_39,male_40_44,male_45_49,male_5_9,male_50_54,male_55_59,male_60_64,male_65_69,male_70_74,male_75_79,male_80_84,male_85_over,male_under_5,mean_commute,mean_commute_boro,mean_commute_nyc,moe_bach_deg,moe_bach_deg_boro,moe_bach_deg_nyc,moe_foreign_born,moe_hh_rent_burd,moe_hh_rent_burd_boro,moe_hh_rent_burd_nyc,moe_lep_rate,moe_lep_rate_boro,moe_lep_rate_nyc,moe_mean_commute,moe_mean_commute_boro,moe_mean_commute_nyc,moe_over65_rate,moe_over65_rate_boro,moe_over65_rate_nyc,moe_poverty_rate,moe_under18_rate,moe_under18_rate_boro,moe_under18_rate_nyc,moe_unemployment_nyc,moe_unemployment_boro,moe_unemployment,neighborhoods,over65_rate,over65_rate_boro,over65_rate_nyc,pct_asian_nh,pct_bach_deg,pct_bach_deg_boro,pct_bach_deg_nyc,pct_black_nh,pct_clean_strts,pct_clean_strts_boro,pct_clean_strts_nyc,pct_foreign_born,pct_hh_rent_burd,pct_hh_rent_burd_boro,pct_hh_rent_burd_nyc,pct_hispanic,pct_other_nh,pct_served_parks,pct_white_nh,pop_2000,pop_2010,pop_acs,pop_change_00_10,poverty_rate,poverty_rate_boro,poverty_rate_nyc,puma,shared_puma,shared_puma_cd,son_issue_1,son_issue_2,son_issue_3,total_lot_area,under18_rate,under18_rate_boro,under18_rate_nyc,unemployment_boro,unemployment,unemployment_nyc,v_pluto,v_acs,v_facdb,v_crime%20FROM%20community_district_profiles&filename=Bronx-1-indicators.csv)


```{r}
whoweare <- read.csv("indicators.csv")

```


## Social and Economic Conditions

### Education(page 6)

#### Elementary School Absenteeism 
```{r}
#Assigning a dataframe which will create the dataframe
percent_esa <- data.frame()

#Locate the health profiles
all_files <- list.files(path = "Health_Profiles/")


#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){

     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file,sep = ""), pages = 6, area = list(c(195, 35, 418, 87)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}\\%", .))
    
     current_info <- tibble(location = current_file, current_stats = percents)
     
     percent_esa <- percent_esa %>% bind_rows(current_info)

}

percent_esa$location <- substr(percent_esa$location,1,nchar(percent_esa$location)-4)#This is to remove .pdf from each district name  
colnames(percent_esa) <- c("District", "Elementary_School_Absenteeism")#
percent_esa $ Elementary_School_Absenteeism <- unlist(percent_esa$Elementary_School_Absenteeism)#This is to flatten the second column

percent_esa #Initiating the dataframe to produce the data


```

#### On-Time High School Graduation

```{r}
percent_othsg <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
     

     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file,sep = ""), pages = 6, area = list(c(226, 299, 417, 361)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}\\%", .))
     

     current_info <- tibble(location = current_file,
                            current_stats = percents)

     percent_othsg <- percent_othsg %>% bind_rows(current_info)

}

percent_othsg$location <- substr(percent_othsg$location,1,nchar(percent_othsg$location)-4)#This is to remove the .pdf from each district
colnames(percent_othsg) <- c("District", "On_time_high_school_graduation")#This is to change the name of the column names
percent_othsg$On_time_high_school_graduation <- unlist(percent_othsg$On_time_high_school_graduation)#This is to flatten the second column

percent_othsg #Initiating the dataframe to produce the data

```

#### Highest Level of Education Achieved

```{r}
percent_hloea <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
     

     current_file <- all_files[i]



     out <- extract_text(paste("Health_Profiles/",current_file,sep = ""), pages = 6, area = list(c(542, 128, 589, 419)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}\\%", .))
   

     current_info <- tibble(location = current_file,
                            current_stats = percents)

     percent_hloea <- percent_hloea %>% bind_rows(current_info)

}

percent_hloea$location <- substr(percent_hloea$location,1,nchar(percent_hloea$location)-4)#This is to remove the .pdf from each district
colnames(percent_hloea) <- c("District", "Less_than_High_School_High_School_graduate_or_some_college_or_College_graduate")#This is to change the name of the column for the dataframe
a <- percent_hloea%>% unnest_wider(Less_than_High_School_High_School_graduate_or_some_college_or_College_graduate) #assigning this to be able to separate and rename the columns in tb1_df

colnames(a)[2:4] <- c("Less than high school", "High School Graduate or some college", "College graduate") #The renaming of each column
           
a #initiating the tb1_df with different column names

```

### Economic Stress (Page 7)
```{r}
EconomicStress <- data.frame()
for(i in 1:59){
  #Change Page 7 from PDF to text
  doc <- pdf_text(paste("Health_Profiles/", all_files[i], sep=""))[[7]] %>% 
    #Standardizes formated and removes blank spaces
    str_replace_all("(\\n)", " ") %>% str_squish()
  #Extracts percentages and districts namer from the the page
df <- data.frame(District = str_extract(all_files[i], "(bx|qn|mn|si|bk)[0-9]{1,4}"),
                 DistrictName=str_to_title(regmatches(doc, regexec("HEALTH PROFILES 2018:\\s*(.*?)\\s*7", doc))[[1]][2]),
                 Poverty=str_extract(str_extract(doc, "Poverty [0-9]{1,2}% [0-9]{1,2}% [0-9]{1,2}%"), "[0-9]{1,2}"),
                 Unemployment=str_extract(str_extract(doc, "Unemployment [0-9]{1,2}% [0-9]{1,2}% [0-9]{1,2}%"), "[0-9]{1,2}"),
                 RentBurden=str_extract(str_extract(doc, "Rent Burden [0-9]{1,2}% [0-9]{1,2}% [0-9]{1,2}%"), "[0-9]{1,2}"),
                 AvertableDeaths=str_extract(str_extract(doc, "[0-9]{1,2}% of deaths could have been averted"), "[0-9]{1,2}"))
EconomicStress <- rbind(EconomicStress, df)
}
```

#### Non-Fatal Assult Hospitalizations 

#### Jail Incarceration

#### Helpful Neighbors

### Housing and Neighbourhood Conditions

#### Air Conditioning

```{r}
# locate the health profiles pdfs(make sure to change to your own directory)
pdf_path = list.files(path = "Health_Profiles/")

#lists the files in the path where our pdf's are stored
AC = matrix(NA, ncol = 1, nrow = 59) 
areas =  c(276, 36, 330, 79)

#iterate through pdf's and extract target data value, being conscious of misc values
for(i in 1:59){
  pdfText = extract_text(paste("Health_Profiles/",pdf_path[i], sep ="" ),pages = 9, area = list(areas))
  values = unlist(str_match_all(pdfText,"[0-9]{1,2}%"))
  if(length(values) == 2){
    AC[i,] = values[2]
  }
  else{
    AC[i,] = values[1]
  }
}

#clean data, turn decimals into percents, turn whole thing into a data frame.
new_ac = gsub("%", "", AC)
AC = apply(new_ac, 2, as.numeric)/100
rm(new_ac)

Districts = substr(pdf_path,start = 0, stop = nchar(pdf_path)- 4)
acRates = data.frame(cbind(Districts, AC))
colnames(acRates) = c("Districts","Air_Conditioning_Rates")
rm(AC)
#lists the files in the path where our pdf's are stored
```

#### Air Pollution


#### Home without Maintenance Defects

```{r}
defect_Rates = matrix(NA, ncol = 1, nrow = 59) 
areas =  c(554, 46, 658, 90)

#iterate through pdf's and extract target data value
for(i in 1:59){
  pdfText = extract_text(paste("Health_Profiles/",pdf_path[i], sep = ""),pages = 9, area = list(areas))
  values = unlist(str_match_all(pdfText,"[0-9]{1,2}%"))
  defect_Rates[i,] = values
}

#clean data, turn decimals into percents, turn whole thing into a data frame.
new_df = gsub("%", "", defect_Rates)
defect_Rates = apply(new_df, 2, as.numeric)/100
rm(new_df)

Homes_wo_defects = data.frame(cbind(Districts, defect_Rates))
colnames(Homes_wo_defects) = c("Districts","Rate_of_renter-occupied_homes")
rm(defect_Rates)
```

#### Homes Reporting Cockroaches

```{r}

roach = matrix(NA, ncol = 1, nrow = 59) 
areas =  c(569, 308, 589, 426)

#iterate through pdf's and extract target data value
for(i in 1:59){
  pdfText = extract_text(paste("Health_Profiles/",pdf_path[i],sep = ""),pages = 9, area = list(areas))
  values = unlist(str_match_all(pdfText,"[0-9]{1,2}%"))
  roach[i,] = values
}

#clean data, turn decimals into percents, turn whole thing into a data frame.
new_roach = gsub("%", "", roach)
roach = apply(new_roach, 2, as.numeric)/100
rm(new_roach)

Districts = substr(pdf_path,start = 0, stop = nchar(pdf_path)- 4)
roachRates = data.frame(cbind(Districts, roach))
colnames(roachRates) = c("Districts","Homes_Reporting_Cockroaches")
rm(roach)

```

#### Bicycle Network Coverage, Pedestrain Injuries and Food Environment
```{r}
Housing <- data.frame()

PercentExtract <- function(file, page, area){
  Ex <- extract_text(file, pages= page, area= list(area)) %>%
    str_replace_all("\n", " ") %>% 
    str_extract("[0-9]{1,2}%") %>%
    removePunctuation()
  return(Ex)
}
# Enviroment variables for Cleaning
WordToNum <- c(no=0, one=1, two=2, three=3, four=4, five=5, six=6, seven=7, eight=8, nine=9, ten=10)

for(i in 1:59) {
  #Identifies the files in their files
  File <- paste("Health_Profiles/", all_files[i], sep="")
  #Creates the data frame
  df <- data.frame(District = str_extract(all_files[i], "(bx|qn|mn|si|bk)[0-9]{1,4}"),
                   #Percentages of Bike Lanes
                   Bike = PercentExtract(File, 10, c(210, 40, 240, 170)),
                   #Pedestrian Injuries per 100k injuries
                   PedInj = str_extract(extract_text(File, pages=10, area=list(c(210, 310, 240, 420))),"[0-9]{1,2}"),
                   #Number of farmers markers in district
                   FarmersMarket = extract_text(File, pages=10, area=list(c(450, 36, 660, 300))) %>% str_replace_all("(\\n)", " ") %>%
                     str_squish() %>% str_extract("(?<=home to\\s)\\w+") %>% revalue(WordToNum,warn_missing = FALSE),
                   #Number of bodegas for every one supermarket
                   Bodegas= extract_text(File, pages=10, area=list(c(400, 310, 540, 580))) %>% str_replace_all("(\\n)", " ") %>%
                     str_squish() %>% str_extract("(?<=there are\\s)\\w+") %>% revalue(WordToNum, warn_missing = FALSE))
  Housing <- rbind(Housing, df)
}
```



## Maternal and Child Health

#### Late or No Parental Care
```{r}
percent_lnpc <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
    
     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file,sep = ""), pages = 11, area = list(c(213, 30, 331, 571)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}.[0-9]{1}\\%", .))

     current_info <- tibble(location = current_file, current_stats = percents)

     percent_lnpc <- percent_lnpc %>% bind_rows(current_info)
}
#I will be doing this to modify the data 
#Note: Some numbers in loops may be repeated because more numbers showed up repeated and required
#a second loop to be removed in certain places which will be explained below 
thevalue <- percent_lnpc$current_stats

#This loop is for keeping a percentage at one district and removing it from all the other districts which is the financial district
for (district in 1:59) {
     current_dis <- (thevalue[[district]]) # to String function binds entire column in one string
     if (("1.3%" %in% current_dis) & (district != 31)) {
          percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "1.3%")
     }
}
#This is to remove the percentage from all the pdf files as it is not important which is the state NYC
thevalue <- percent_lnpc$current_stats
for (district in 1:59) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "6.7%")
}

#This is to remove the borough percentages from the current stats of districts Bronx
thevalue <- percent_lnpc$current_stats
for (district in 19:30) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "10.9%")
}
#Some of the borough percentages were not erased so i did another loop to be able to remove them from where they were not removed 
thevalue <- percent_lnpc$current_stats
for (district in 19:30) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "10.9%")
}
#This is to remove the borough district Brooklyn percentage from the current stats
thevalue <- percent_lnpc$current_stats
for (district in 1:18) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "6.2%")
}
#This is to remove the borough district Manhattan percentage from the current stats
thevalue <- percent_lnpc$current_stats
for (district in 31:42) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "4.9%")
}
#This is to remove the borough district Queens percentage from the current stats
thevalue <- percent_lnpc$current_stats
for (district in 43:56) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "7.9%")
}
#Some were not removed because they were repeated so i did another loop in the districts that needed to be removed  
thevalue <- percent_lnpc$current_stats
for (district in 43:56) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "7.9%")
}
#This is to remove the borough district staten island percentage from the current stats
thevalue <- percent_lnpc$current_stats
for (district in 57:59) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "2.5%")
}
#This was a percentage found in the current stats that was highly unnecessary and was removed 
thevalue <- percent_lnpc$current_stats
for (district in 57:59) {
     current_dis <- thevalue[[district]]
     percent_lnpc$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "7.9%")
}
#Below is to remove commas and to modify and organize the data
thevalue <- percent_lnpc$current_stats
for (district in 1:59) {
 
    percent_lnpc$current_stats[[district]] <- percent_lnpc$current_stats[[district]] %>%
          str_remove_all(.,",") %>%
          str_remove(.,"%") %>%
          str_trim() %>%
          as.numeric(.)
         
            
}
percent_lnpc$location <- substr(percent_lnpc$location,1,nchar(percent_lnpc$location)-4) # to remove .pdf from each district 
colnames(percent_lnpc) <- c("District", "late_or_no_prenatal_care") #changing the names of the column 
percent_lnpc$late_or_no_prenatal_care <- unlist(percent_lnpc$late_or_no_prenatal_care) # this is to flatten the second column


percent_lnpc #Initiating the dataframe to produce the data
```

#### Preterm Births
```{r}

percent_bf <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
     
     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file, sep = ""), pages = 11, area = list(c(385, 28, 468, 445)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}.[0-9]{1}\\%", .))

     current_info <- tibble(location = current_file, current_stats = percents)

     percent_bf <- percent_bf %>% bind_rows(current_info)

}

#Note: Some numbers in loops may be repeated because more numbers showed up repeated and required
#a second loop to be removed in certain places which will be explained below 
thedat <- percent_bf$current_stats


#This loop is for keeping a percentage at one district and removing it from all the other districts which is the greenpoint and williamsburg district
for (district in 1:59) {
        current_dis <- (thedat[[district]]) 
        if (("5.4%" %in% current_dis) & (district != 1)) {
                percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "5.4%")
        }
}
#This is to remove the percentage from all the pdf files as it is not important which is the state NYC
thedat <- percent_bf$current_stats
for (district in 1:59) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.7%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough bronx
thedat <- percent_bf$current_stats
for (district in 19:30) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "9.7%")

}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Brooklyn
thedat <- percent_bf$current_stats
for (district in 1:18) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.3%")

}
#Some percentages of brooklyn were not removed so i did another for loop to be able to remove them 
thedat <- percent_bf$current_stats
for (district in 16:18) {
    current_dis <- thedat[[district]]
   percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.3%")

}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Manhattan
thedat <- percent_bf$current_stats
for (district in 31:42) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.3%")
}
#Some percentages of Manhattan were not removed so i did another for loop to be able to remove them 
thedat <- percent_bf$current_stats
for (district in 34:36) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.3%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Queens
thedat <- percent_bf$current_stats
for (district in 43:56) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.5%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Staten Island
thedat <- percent_bf$current_stats
for (district in 57:59) {
        current_dis <- thedat[[district]]
        percent_bf$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "8.6%")
}
#Below is to remove commas and to modify and organize the data
thedat <- percent_bf$current_stats
for (district in 1:59) {
percent_bf$current_stats[[district]] <- percent_bf$current_stats[[district]] %>%
 
   
str_remove_all(.,",") %>%
str_remove(.,"%") %>%
str_trim() %>%
as.numeric(.)
}
percent_bf$location <- substr(percent_bf$location,1,nchar(percent_bf$location)-4) # to remove .pdf from each district
colnames(percent_bf) <- c("District", "pretermbirth") # changing the names of each column
percent_bf$pretermbirth <- unlist(percent_bf$pretermbirth) # this is to flatten the second column


percent_bf #Initiating the dataframe to produce the data
```

#### Teen Births
```{r}
percent_tf <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){

     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file, sep = ""), pages = 11, area = list(c(550, 309, 596.5, 649)))

     percents <- out %>% regmatches(., gregexpr("[1-9]{1}[0-9]{0,1}\\.[0-9]{1}", .))

     current_info <- tibble(location = current_file,
                            current_stats = percents)

     percent_tf <- percent_tf %>% bind_rows(current_info)

}


percent_tf$location <- substr(percent_tf$location,1,nchar(percent_tf$location)-4)# to remove .pdf from each district
colnames(percent_tf) <- c("District", "teen_births")# changing the names of each column
percent_tf$teen_births<- unlist(percent_tf$teen_births)# this is to flatten the second column


percent_tf #Initiating the dataframe to produce the data
```

#### Childhood Obesity
```{r}

```
#### Avoidable Hospitalization Among Children
```{r}

```

#### Children Asthma Emergency Department Visits
```{r}

```

## Healthy Living

```{r}
Healthy_Living = matrix(NA, ncol = 4, nrow = 59)
areas = c(518, 249, 686, 290)

for(i in 1:59){
  pdfTxt = extract_text(paste("Health_Profiles/",pdf_path[i],sep = ""),pages = 13, area = list(areas))
  vals = unlist(str_match_all(pdfTxt,"[0-9]{1,2}%"))
  Healthy_Living[i,] = vals 
}

new_hl = gsub("%", "", Healthy_Living)
Healthy_Living = apply(new_hl, 2, as.numeric)/100
rm(new_hl)

Healthy_Living = data.frame(cbind(District, Healthy_Living))
colnames(Healthy_Living) <- c("Districts",    
                              "Any_physical_activity_in_the_past_30_days",
                      "At_least_one_serving_of_fruits_or_vegetables_per_day",
                              "One_or_more_12-ounce_sugary_drinks_per_day",
                              "Current_Smokers")
```


## Healthcare

```{r}

ValuesWithCommas <- function(file, page, area){
  Val <- extract_text(file, pages= page, area= list(area)) %>%
    str_extract_all("[0-9]") %>% paste(unlist(.), collapse = "")
  return(Val)
}

Healthcare <- data.frame()
for(i in 1:59){
  #Identifies the documents
 doc <- paste("Health_Profiles/",all_files[i], sep="")
 df <- data.frame(
    District[i],
    NoInsurance = PercentExtract(doc, 14, c(251, 75, 290, 240)),
    WithoutCare = PercentExtract(doc, 14, c(270, 75, 430, 240)),
    AvoidableHosp = ValuesWithCommas(doc, 14, c(410, 309, 435, 520)),
    Falls = ValuesWithCommas(doc, 14, c(577, 308, 600, 520)),
    HPVVacc = PercentExtract(doc, 15, c(321, 35, 445, 75)),
    FluVacc = PercentExtract(doc, 15, c(321, 306, 445, 355)))
 Healthcare <- rbind(df, Healthcare)
  }
```

## Health Outcomes

#### Obesity, diabetes and hypertension
```{r}
Health_Outcomes = matrix(NA, ncol = 3, nrow = 59)
HOareas =  c(240, 174, 396, 241)

for(i in 1:59){
  pdfText = extract_text(paste("Health_Profiles/",all_files[i],sep = ""),pages = 16, area = list(HOareas))
  values = unlist(str_match_all(pdfText,"[0-9]{1,2}%"))
  Health_Outcomes[i,] = values
}

new_ho = gsub("%", "", Health_Outcomes)
Health_Outcomes = apply(new_ho, 2, as.numeric)/100
rm(new_ho)

Health_Outcomes = data.frame(cbind(Districts, Health_Outcomes))
colnames(Health_Outcomes) = c("Districts", "Obesity_Rates", "Diabetes_Rates", "Hypertension_Rates")
```


#### New HIV Diagnosis and New hepatitis C reports
```{r}

FromGraph <- function(file, page, area){
  Graph <- extract_text(file, pages= page, area= list(area)) %>% str_remove_all("\\\n") %>% 
    str_extract(., "[0-9]{1,3}\\.[0-9]{1}") %>% as.numeric(as.character(.))
  return(Graph)
}
HIVHep <- data.frame()
for(i in 1:59){
  doc <- paste("Health_Profiles/", all_files[i], sep="")
  df <- data.frame(
    District,
    NewHiv = FromGraph(doc, 16, c(490, 64, 660, 510)),
    NewHep = FromGraph(doc, 17, c(178, 61, 320, 510)))
  HIVHep <- rbind(HIVHep, df)
}
```

#### Binge Drinking
```{r}
percent_bdr <- data.frame()

#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
     
     current_file <- all_files[i]

out <- extract_text(paste("Health_Profiles/",current_file,sep = ""), pages = 17, area = list(c(406, 40, 482, 578)))

percents <- out %>% regmatches(., gregexpr("[0-9]{1,2}\\%", .))

current_info <- tibble(location = current_file, current_stats = percents)

percent_bdr <- percent_bdr %>% bind_rows(current_info)

}

the_val <- percent_bdr$current_stats
#I will be doing this to modify the data 
#Note: Some numbers in loops may be repeated because more numbers showed up repeated and required
#a second loop to be removed in certain places which will be explained below 
district <- 35
#This loop is for keeping a percentage at one current stats and removing it from all the other current stats which is bensonhurst
for (district in 1:59) {

     current_dis <- (the_val[[district]]) # to String function binds entire column in one string
     if (("9%" %in% current_dis) & (district != 3)) {
          percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "9%")
     }
}
#This is to remove the percentage from all the pdf files as it is not important which is the state NYC
the_val <- percent_bdr$current_stats
for (district in 1:59) {
     current_dis <- the_val[[district]]
     percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "17%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough bronx
the_val <- percent_bdr$current_stats
for (district in 19:30) {
     current_dis <- the_val[[district]]
     percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "14%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Brooklyn
the_val <- percent_bdr$current_stats
for (district in 1:18) {
     current_dis <- the_val[[district]]
     percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "15%")
}
#This is to remove the percentage from all the pdf files that still remained from the other loop before this one 
the_val <- percent_bdr$current_stats
for (district in 3:6) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "15%")
}
#This is another loop to remove nyc that still had remained on the current stats
the_val <- percent_bdr$current_stats
for (district in 6:11) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "17%")
}
#This is another loop to remove nyc that still had remained on the current stats
the_val <- percent_bdr$current_stats
for (district in 17:19) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "17%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Manhattan
the_val <- percent_bdr$current_stats
for (district in 31:42) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "25%")
}
#This is another loop to remove nyc that still had remained on the current stats
the_val <- percent_bdr$current_stats
for (district in 42:55) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "17%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Queens
the_val <- percent_bdr$current_stats
for (district in 43:56) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "15%")
}
#This is to remove the percentage from all the pdf files as it is not important which is the borough Staten Island
the_val <- percent_bdr$current_stats
for (district in 57:59) {
        current_dis <- the_val[[district]]
        percent_bdr$current_stats[[district]] <- str_remove(string = toString(current_dis), pattern = "18%")
}
the_val <- percent_bdr$current_stats
#Below is to remove commas and to modify and organize the data
for (district in 1:59) {
       percent_bdr$current_stats[[district]] <- percent_bdr$current_stats[[district]] %>%
                str_remove_all(.,",") %>%
                str_remove(.,"%") %>%
               str_trim() %>%
                as.numeric(.)
}


percent_bdr$location <- substr(percent_bdr$location,1,nchar(percent_bdr$location)-4) # to remove .pdf from each district
colnames(percent_bdr) <- c("District", "binge_drinking") #changing the names of each of the columns
percent_bdr$binge_drinking <- unlist(percent_bdr$binge_drinking) #this is to flatten the second column


percent_bdr #Initiating the dataframe to produce the data
```

#### Psychiatric hospitalizations

```{r}
percent_ph <- data.frame()


#This entire for loop will read all of the files based on the location on where the extract text is based on the coordinates and will produce the data in that same spot of each pdf page
for(i in seq_along(all_files)){
    

     current_file <- all_files[i]

     out <- extract_text(paste("Health_Profiles/",current_file, sep= ""), pages = 17, area = list(c(555, 302, 584, 575)))

     percents <- out %>% regmatches(., gregexpr("[0-9]{0,1},{0,1}[0-9]{3,4}", .))

     current_info <- tibble(location = current_file,
                            current_stats = percents)

     percent_ph <- percent_ph %>% bind_rows(current_info)

}
the_val <- percent_ph$current_stats


percent_ph$location <- substr(percent_ph$location,1,nchar(percent_ph$location)-4)#This is to remove the .pdf from each district
colnames(percent_ph) <- c("District", "Psychiatric_Hospitilizations")#This is to change the names of each column
percent_ph$Psychiatric_Hospitilizations<- unlist(percent_ph$Psychiatric_Hospitilizations)#This is to flatten the second column

percent_ph #Initiating the dataframe to produce the data

```

#### Infant mortality
```{r}

```

#### Premature death
```{r}

```

#Binder
```{r}
#Binds all the frames together
FinalFrame <- left_join(EconomicStress, Housing, by="District") %>% left_join(., Healthcare, by="District") %>% left_join(., HIVHep, by="District")

#Removes the singular frames & Misc
rm(Healthcare, HIVHep, Housing, EconomicStress, doc, i, WordToNum, pdf, File, FromGraph, PercentExtract, download.folder, df, ValuesWithCommas)
```




