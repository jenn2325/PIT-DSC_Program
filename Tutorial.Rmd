---
title: "Onboarding Tutorial"
author: "Jen Wang"
date: "6/1/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# PART I: Web Scrapping Tutorial
<br>
<h2>Rselenium Package & rvest Package<h2/>

Install these two packages and comment out the codes.
```{r}
#install.packages("Rselenium")
#install.packages("rvest")
library(RSelenium)
library(rvest)
```

#### Dynamic vs. Static Websites
**Static Web Pages** are web pages that display the fixed contents and deliver the same pages to all users;<br>
**Dynamic Web Pages** are pages that can display different contents and information change occurs frequently, some also provide user interaction.

If you tried scraping a Dynamic web page, you might not obtain dynamic information by `rvest::read_html()`.

As such, two option can be used to overcome this issue:<br>
<OL TYPE=”I”>
<LI> Save the web page in complete format
<LI> Using `Rselenium` Package to obtain dynamic webpages.
</OL>
    

  
#### 1. Save the web page in complete format:
* Using Google Chrome Browser to open the web page.
* Download the page as  "webpage, complete" format.
* Using `rvest::read_html()` to read the webpage in r.

![](Screen Shot 2021-06-03 at 10.07.25 PM.png)

#### 2. Rselenium Package:

`Rselenium` Package is a tool to navigate websites and it can be combined with the `rvest` package to scrape dynamic web pages.

**Prerequisites**
<OL TYPE=”I”>
<LI> Check which version your browser is running on. Depending on your browser type, I am using Chrome here. Click the top right three dots -> Help -> About Google Chrome to see which version you are on.
![](Screen Shot 2021-06-03 at 11.20.09 PM.png)
<br><br>
For mine, it indicates that Chrome is running on Version 91.0.4472.77(Version 91)
<br><br>
![](Screen Shot 2021-06-03 at 11.22.31 PM.png)


<LI> Next [download](https://chromedriver.chromium.org/downloads) the current Selenium web drivers for your Chrome version. 
![](Screen Shot 2021-06-03 at 11.56.47 PM.png)
<br><br>
Then select the chromedriver corresponding your computer system.(I am using mac here)
<br><br>
![](Screen Shot 2021-06-03 at 11.57.03 PM.png)

<LI> Download the latest stable version of [Selenium Server](https://www.selenium.dev/downloads/) and save it to the appropriate folder. 
![](Screen Shot 2021-06-04 at 12.08.25 AM.png)

<LI> Open the terminal and change the directory to where you save the Selenium Server .jar and then enter `java -Dwebdriver.chrome.driver=chromedriver  -jar selenium-server-standalone-3.141.59.jar`. Here `-jar selenium-server-standalone-3.141.59.jar` is the name of the file you just downloaded.
![](Screen Shot 2021-06-04 at 12.13.51 AM.png)
<br><br>
Once you see that *"Selenium Server is up and running on port 4444"*, then Selenium Server has been successfully installed and ready to use. 
<br><br>
![](Screen Shot 2021-06-04 at 12.17.33 AM.png)

</OL>


```{r results = FALSE}
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4444, browserName ="chrome")
remDr$open()
```



If everything above worked correctly, a new chrome window will open. This window should look like this:
![](Screen Shot 2021-06-04 at 12.28.03 AM.png)

[Note]: For mac users, you might need to change Security&Privacy Setting to allow the chrome driver to function.

Then you are able to read the dynamic website using following code:
```{r results= FALSE}
remDr$navigate("https://www.columbia.edu/")
page <- rvest::read_html(remDr$getPageSource()[[1]])
```
<br><br>

<h3> Check Permission to access web pages. <h3/>

Always to check if it has permissions to access page(s)
```{r}
#install.packages("robotstxt")
robotstxt::paths_allowed("https://www.columbia.edu/")
```
If "TRUE" is returned, then we continue the process; otherwise you you should google or reach out for help.

<h3> Understanding the Structure of an HTML Page <h3/>

HTML is organized using tags, which are surrounded by <> symbols. 
A basic html page structure should look like this:

```{r eval=FALSE}
<!DOCTYPE html>
<html>
<head>
<title>Page Title</title>
</head>
<body>

<h1>My First Heading</h1>
<p>My first paragraph.</p>

</body>
</html>

```

Use the  `html_nodes()` and `html_text()` functions respectively to search for this tag and retrieve the relative text. You will need to put the path in the `html_nodes()`. To get the path, right click the particular line from the web on Chrome, and choose “Inspect”. -> Right click the choosen line, click “copy->copy full Xpath”. Then we will get the path of the line we choose from the web.` 

For example if we want to extract word "Commencement" from Columbia website:<br>
![](Screen Shot 2021-06-04 at 1.29.07 AM.png)

![](Screen Shot 2021-06-04 at 1.29.43 AM.png)

```{r message = FALSE}
library(tidyverse)
page %>% 
  html_nodes(xpath = "/html/body/div[1]/div[3]/main/div[2]/section/div/div/div/article/div/div[2]/div[3]/div/div/div/div[4]/div/a/div/div/div/span") %>% 
  html_text()
```

# PART II: PDF Parsing Tutorial

[Note"] There are many resources for parsing pdf documents. I will introduce `pdftools` package and `tabulizer` package in this tutorial.

<h3> Install and load the packages <h3/>
```{r}
#install.packages("pdftools")
#install.packages("tabulizer")
library(pdftools)
library(tabulizer)
```

<h3> Load the pdf file <h3/>

```{r}
download.file("https://www.cdc.gov/nchs/data/vsrr/vsrr012-508.pdf","document.pdf")
document <- pdf_text("document.pdf")
```

<h3> Clean pdf data <h3/>

* Using `read_lines()` function reads the lines.
* Using `str_trim()` to remove whitespace from start and end of string.
* Using `strsplit()` to separate lines from each other, we will need to use regular expressions. You could test your regular expression [here](https://regex101.com).
* Using `ldply()` to transform the result from a list to a data frame.
* Last step is to add the variables name into a final data frame:

```{r}
document <- document %>% 
  .[6] %>% 
  read_lines() %>% 
  .[6:17] %>% 
  str_trim() %>% 
  strsplit(split = "\\s{2,}") %>% 
  plyr::ldply()
document[1,][2:5] <- paste0(c(rep("2020 ",2), rep("2019 ",2)), document[1,][2:5])
colnames(document) <- document[1,]
document <- document[-1,]
document
```


<h2> Extracting Tables Using Tabulizer Package<h2/>

```{r}
table <- tabulizer::extract_tables(file = "https://www.cdc.gov/nchs/data/vsrr/vsrr012-508.pdf", pages = 6, output = "data.frame")[[1]]
table
```

<h3> Clean the table <h3/>

```{r}
table <- table[,c(1,3,5,6,8)] 
colnames(table) <- paste0(c("Age of mother", rep("2020 ", 2), rep("2019 ",2)),table[1,])
table <- table[-1,]
table
```

